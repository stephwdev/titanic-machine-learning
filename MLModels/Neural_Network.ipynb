{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras import optimizers, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../titanic/cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  SibSp  Parch     Fare  male  Q  S\n",
       "0         0       3  22.0      1      0   7.2500     1  0  1\n",
       "1         1       1  38.0      1      0  71.2833     0  0  0\n",
       "2         1       3  26.0      0      0   7.9250     0  0  1\n",
       "3         1       1  35.0      1      0  53.1000     0  0  1\n",
       "4         0       3  35.0      0      0   8.0500     1  0  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(889, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train.to_numpy()\n",
    "X = data[:,1:]\n",
    "y = data[:,0]\n",
    "# y = to_categorical(y,num_classes=2)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.10, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,input_dim=8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321\n",
      "Trainable params: 321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/stephaniewalsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 224us/step - loss: 0.9203 - accuracy: 0.3613 - val_loss: 0.8682 - val_accuracy: 0.4045\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.8328 - accuracy: 0.3550 - val_loss: 0.7960 - val_accuracy: 0.3820\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 20us/step - loss: 0.7700 - accuracy: 0.3363 - val_loss: 0.7488 - val_accuracy: 0.3708\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.7296 - accuracy: 0.3562 - val_loss: 0.7173 - val_accuracy: 0.3483\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.7035 - accuracy: 0.4450 - val_loss: 0.6956 - val_accuracy: 0.4831\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.6859 - accuracy: 0.5788 - val_loss: 0.6796 - val_accuracy: 0.6067\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6736 - accuracy: 0.6288 - val_loss: 0.6693 - val_accuracy: 0.6629\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6658 - accuracy: 0.6363 - val_loss: 0.6603 - val_accuracy: 0.6742\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 35us/step - loss: 0.6594 - accuracy: 0.6375 - val_loss: 0.6532 - val_accuracy: 0.6629\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.6544 - accuracy: 0.6400 - val_loss: 0.6474 - val_accuracy: 0.6629\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.6504 - accuracy: 0.6375 - val_loss: 0.6424 - val_accuracy: 0.6629\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.6465 - accuracy: 0.6388 - val_loss: 0.6373 - val_accuracy: 0.6629\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.6427 - accuracy: 0.6388 - val_loss: 0.6337 - val_accuracy: 0.6629\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.6398 - accuracy: 0.6438 - val_loss: 0.6295 - val_accuracy: 0.6742\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6369 - accuracy: 0.6463 - val_loss: 0.6260 - val_accuracy: 0.6742\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6347 - accuracy: 0.6475 - val_loss: 0.6227 - val_accuracy: 0.6742\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6327 - accuracy: 0.6500 - val_loss: 0.6193 - val_accuracy: 0.6854\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.6307 - accuracy: 0.6538 - val_loss: 0.6169 - val_accuracy: 0.7079\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6292 - accuracy: 0.6600 - val_loss: 0.6143 - val_accuracy: 0.7191\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.6278 - accuracy: 0.6662 - val_loss: 0.6124 - val_accuracy: 0.7079\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.6262 - accuracy: 0.6787 - val_loss: 0.6099 - val_accuracy: 0.7191\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.6251 - accuracy: 0.6862 - val_loss: 0.6078 - val_accuracy: 0.7079\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 0.6234 - accuracy: 0.6925 - val_loss: 0.6061 - val_accuracy: 0.7079\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6224 - accuracy: 0.6913 - val_loss: 0.6040 - val_accuracy: 0.6854\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.6212 - accuracy: 0.6850 - val_loss: 0.6022 - val_accuracy: 0.6742\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.6202 - accuracy: 0.6825 - val_loss: 0.6011 - val_accuracy: 0.6854\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 21us/step - loss: 0.6196 - accuracy: 0.6825 - val_loss: 0.6000 - val_accuracy: 0.6854\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 35us/step - loss: 0.6187 - accuracy: 0.6812 - val_loss: 0.5991 - val_accuracy: 0.6742\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6180 - accuracy: 0.6825 - val_loss: 0.5978 - val_accuracy: 0.6742\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.6173 - accuracy: 0.6812 - val_loss: 0.5972 - val_accuracy: 0.6742\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6167 - accuracy: 0.6837 - val_loss: 0.5960 - val_accuracy: 0.6742\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.6162 - accuracy: 0.6862 - val_loss: 0.5955 - val_accuracy: 0.6629\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6158 - accuracy: 0.6862 - val_loss: 0.5944 - val_accuracy: 0.6629\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6152 - accuracy: 0.6862 - val_loss: 0.5932 - val_accuracy: 0.6629\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6148 - accuracy: 0.6850 - val_loss: 0.5930 - val_accuracy: 0.6629\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.6144 - accuracy: 0.6888 - val_loss: 0.5925 - val_accuracy: 0.6629\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.6138 - accuracy: 0.6913 - val_loss: 0.5916 - val_accuracy: 0.6629\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.6133 - accuracy: 0.6888 - val_loss: 0.5907 - val_accuracy: 0.6629\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.6130 - accuracy: 0.6913 - val_loss: 0.5896 - val_accuracy: 0.6629\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.6127 - accuracy: 0.6913 - val_loss: 0.5887 - val_accuracy: 0.6629\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 0.6122 - accuracy: 0.6875 - val_loss: 0.5881 - val_accuracy: 0.6629\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.6120 - accuracy: 0.6862 - val_loss: 0.5875 - val_accuracy: 0.6742\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.6118 - accuracy: 0.6913 - val_loss: 0.5869 - val_accuracy: 0.6742\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.6114 - accuracy: 0.6900 - val_loss: 0.5861 - val_accuracy: 0.6742\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 19us/step - loss: 0.6112 - accuracy: 0.6900 - val_loss: 0.5854 - val_accuracy: 0.6742\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.6110 - accuracy: 0.6888 - val_loss: 0.5850 - val_accuracy: 0.6854\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.6109 - accuracy: 0.6862 - val_loss: 0.5849 - val_accuracy: 0.6854\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6106 - accuracy: 0.6888 - val_loss: 0.5841 - val_accuracy: 0.6854\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6103 - accuracy: 0.6900 - val_loss: 0.5840 - val_accuracy: 0.6854\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.6102 - accuracy: 0.6900 - val_loss: 0.5834 - val_accuracy: 0.6854\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Sequential()\n",
    "new_model.add(Dense(1,input_dim=8,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 220us/step - loss: 5.6389 - accuracy: 0.6162 - val_loss: 5.1104 - val_accuracy: 0.6404\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 32us/step - loss: 4.6937 - accuracy: 0.6363 - val_loss: 2.4501 - val_accuracy: 0.6629\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 43us/step - loss: 2.0481 - accuracy: 0.6700 - val_loss: 1.2760 - val_accuracy: 0.6854\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 59us/step - loss: 1.2052 - accuracy: 0.6913 - val_loss: 1.1780 - val_accuracy: 0.5393\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 42us/step - loss: 1.1165 - accuracy: 0.5900 - val_loss: 1.0642 - val_accuracy: 0.6404\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 21us/step - loss: 1.1806 - accuracy: 0.6275 - val_loss: 1.1475 - val_accuracy: 0.4831\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 1.4845 - accuracy: 0.5713 - val_loss: 0.8249 - val_accuracy: 0.7079\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 21us/step - loss: 1.5031 - accuracy: 0.5813 - val_loss: 1.0364 - val_accuracy: 0.6742\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 39us/step - loss: 1.1424 - accuracy: 0.6100 - val_loss: 1.2400 - val_accuracy: 0.6292\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 1.2330 - accuracy: 0.6062 - val_loss: 3.9024 - val_accuracy: 0.4045\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 2.1758 - accuracy: 0.6200 - val_loss: 1.0954 - val_accuracy: 0.7528\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 44us/step - loss: 1.2123 - accuracy: 0.6488 - val_loss: 1.2836 - val_accuracy: 0.6180\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.4298 - accuracy: 0.5863 - val_loss: 0.7756 - val_accuracy: 0.7640\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.7743 - accuracy: 0.6675 - val_loss: 2.3053 - val_accuracy: 0.3708\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 35us/step - loss: 1.4397 - accuracy: 0.5763 - val_loss: 1.8978 - val_accuracy: 0.6404\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 1.3483 - accuracy: 0.5725 - val_loss: 0.7529 - val_accuracy: 0.7528\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 1.0914 - accuracy: 0.6212 - val_loss: 1.5958 - val_accuracy: 0.6292\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.5052 - accuracy: 0.5788 - val_loss: 0.9397 - val_accuracy: 0.6404\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 45us/step - loss: 1.3690 - accuracy: 0.5863 - val_loss: 1.0457 - val_accuracy: 0.6067\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 29us/step - loss: 1.2720 - accuracy: 0.6237 - val_loss: 0.7211 - val_accuracy: 0.7640\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 1.0439 - accuracy: 0.6438 - val_loss: 1.2509 - val_accuracy: 0.6067\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.6355 - accuracy: 0.5675 - val_loss: 0.8686 - val_accuracy: 0.7416\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 0.9519 - accuracy: 0.6237 - val_loss: 2.1657 - val_accuracy: 0.4157\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 1.3653 - accuracy: 0.5925 - val_loss: 0.7707 - val_accuracy: 0.6629\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 25us/step - loss: 1.2401 - accuracy: 0.6112 - val_loss: 0.6285 - val_accuracy: 0.6966\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 1.2618 - accuracy: 0.6187 - val_loss: 0.7911 - val_accuracy: 0.6292\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.1028 - accuracy: 0.6350 - val_loss: 0.8949 - val_accuracy: 0.6404\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 33us/step - loss: 1.0054 - accuracy: 0.6212 - val_loss: 1.3435 - val_accuracy: 0.6292\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 26us/step - loss: 1.1990 - accuracy: 0.6400 - val_loss: 0.6079 - val_accuracy: 0.7191\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.2550 - accuracy: 0.6025 - val_loss: 1.9801 - val_accuracy: 0.6292\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 32us/step - loss: 1.1793 - accuracy: 0.6525 - val_loss: 2.5716 - val_accuracy: 0.3708\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.3678 - accuracy: 0.6288 - val_loss: 0.8276 - val_accuracy: 0.6966\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.8687 - accuracy: 0.6488 - val_loss: 2.0308 - val_accuracy: 0.3708\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 31us/step - loss: 1.0806 - accuracy: 0.6388 - val_loss: 0.5585 - val_accuracy: 0.7079\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 39us/step - loss: 1.0895 - accuracy: 0.6012 - val_loss: 0.8590 - val_accuracy: 0.6180\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 30us/step - loss: 1.4647 - accuracy: 0.5725 - val_loss: 0.6809 - val_accuracy: 0.7416\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.8417 - accuracy: 0.6712 - val_loss: 0.8837 - val_accuracy: 0.4270\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 62us/step - loss: 1.0857 - accuracy: 0.6212 - val_loss: 0.6345 - val_accuracy: 0.6517\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 27us/step - loss: 1.5408 - accuracy: 0.5487 - val_loss: 0.5822 - val_accuracy: 0.7079\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 0.9561 - accuracy: 0.6325 - val_loss: 0.6001 - val_accuracy: 0.6966\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 1.0626 - accuracy: 0.6275 - val_loss: 1.0233 - val_accuracy: 0.6292\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 1.0847 - accuracy: 0.6200 - val_loss: 0.7518 - val_accuracy: 0.6404\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 19us/step - loss: 1.1250 - accuracy: 0.6087 - val_loss: 2.6032 - val_accuracy: 0.4045\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 24us/step - loss: 1.5582 - accuracy: 0.5938 - val_loss: 0.6304 - val_accuracy: 0.7416\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 23us/step - loss: 1.0702 - accuracy: 0.6275 - val_loss: 0.5211 - val_accuracy: 0.7528\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 20us/step - loss: 1.2835 - accuracy: 0.5925 - val_loss: 0.6667 - val_accuracy: 0.6854\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 20us/step - loss: 1.0944 - accuracy: 0.6187 - val_loss: 0.7357 - val_accuracy: 0.7303\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.7352 - accuracy: 0.7088 - val_loss: 1.2436 - val_accuracy: 0.4157\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 22us/step - loss: 0.9333 - accuracy: 0.6488 - val_loss: 0.9258 - val_accuracy: 0.5281\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 20us/step - loss: 1.3064 - accuracy: 0.5938 - val_loss: 1.0440 - val_accuracy: 0.4045\n"
     ]
    }
   ],
   "source": [
    "history2 = new_model.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(32,input_dim=8,activation='sigmoid'))\n",
    "model_2.add(Dense(32,activation='sigmoid'))\n",
    "model_2.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/30\n",
      "800/800 [==============================] - 0s 334us/step - loss: 0.6711 - accuracy: 0.6162 - val_loss: 0.6676 - val_accuracy: 0.6292\n",
      "Epoch 2/30\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6693 - accuracy: 0.6162 - val_loss: 0.6658 - val_accuracy: 0.6292\n",
      "Epoch 3/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6680 - accuracy: 0.6162 - val_loss: 0.6643 - val_accuracy: 0.6292\n",
      "Epoch 4/30\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6668 - accuracy: 0.6162 - val_loss: 0.6631 - val_accuracy: 0.6292\n",
      "Epoch 5/30\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.6660 - accuracy: 0.6162 - val_loss: 0.6616 - val_accuracy: 0.6292\n",
      "Epoch 6/30\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6651 - accuracy: 0.6162 - val_loss: 0.6607 - val_accuracy: 0.6292\n",
      "Epoch 7/30\n",
      "800/800 [==============================] - 0s 33us/step - loss: 0.6644 - accuracy: 0.6162 - val_loss: 0.6598 - val_accuracy: 0.6292\n",
      "Epoch 8/30\n",
      "800/800 [==============================] - 0s 30us/step - loss: 0.6638 - accuracy: 0.6162 - val_loss: 0.6592 - val_accuracy: 0.6292\n",
      "Epoch 9/30\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.6633 - accuracy: 0.6162 - val_loss: 0.6579 - val_accuracy: 0.6292\n",
      "Epoch 10/30\n",
      "800/800 [==============================] - 0s 25us/step - loss: 0.6625 - accuracy: 0.6162 - val_loss: 0.6571 - val_accuracy: 0.6292\n",
      "Epoch 11/30\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6619 - accuracy: 0.6162 - val_loss: 0.6562 - val_accuracy: 0.6292\n",
      "Epoch 12/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6614 - accuracy: 0.6162 - val_loss: 0.6554 - val_accuracy: 0.6292\n",
      "Epoch 13/30\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6609 - accuracy: 0.6162 - val_loss: 0.6547 - val_accuracy: 0.6292\n",
      "Epoch 14/30\n",
      "800/800 [==============================] - 0s 40us/step - loss: 0.6604 - accuracy: 0.6162 - val_loss: 0.6540 - val_accuracy: 0.6292\n",
      "Epoch 15/30\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6598 - accuracy: 0.6162 - val_loss: 0.6533 - val_accuracy: 0.6292\n",
      "Epoch 16/30\n",
      "800/800 [==============================] - 0s 32us/step - loss: 0.6593 - accuracy: 0.6162 - val_loss: 0.6527 - val_accuracy: 0.6292\n",
      "Epoch 17/30\n",
      "800/800 [==============================] - 0s 39us/step - loss: 0.6589 - accuracy: 0.6162 - val_loss: 0.6520 - val_accuracy: 0.6292\n",
      "Epoch 18/30\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.6584 - accuracy: 0.6162 - val_loss: 0.6515 - val_accuracy: 0.6292\n",
      "Epoch 19/30\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6580 - accuracy: 0.6162 - val_loss: 0.6508 - val_accuracy: 0.6292\n",
      "Epoch 20/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6575 - accuracy: 0.6162 - val_loss: 0.6503 - val_accuracy: 0.6292\n",
      "Epoch 21/30\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6570 - accuracy: 0.6162 - val_loss: 0.6496 - val_accuracy: 0.6292\n",
      "Epoch 22/30\n",
      "800/800 [==============================] - 0s 28us/step - loss: 0.6567 - accuracy: 0.6162 - val_loss: 0.6489 - val_accuracy: 0.6292\n",
      "Epoch 23/30\n",
      "800/800 [==============================] - 0s 37us/step - loss: 0.6562 - accuracy: 0.6162 - val_loss: 0.6484 - val_accuracy: 0.6292\n",
      "Epoch 24/30\n",
      "800/800 [==============================] - 0s 34us/step - loss: 0.6558 - accuracy: 0.6162 - val_loss: 0.6477 - val_accuracy: 0.6292\n",
      "Epoch 25/30\n",
      "800/800 [==============================] - 0s 35us/step - loss: 0.6555 - accuracy: 0.6162 - val_loss: 0.6472 - val_accuracy: 0.6292\n",
      "Epoch 26/30\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6551 - accuracy: 0.6162 - val_loss: 0.6466 - val_accuracy: 0.6292\n",
      "Epoch 27/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6546 - accuracy: 0.6162 - val_loss: 0.6460 - val_accuracy: 0.6292\n",
      "Epoch 28/30\n",
      "800/800 [==============================] - 0s 36us/step - loss: 0.6542 - accuracy: 0.6162 - val_loss: 0.6456 - val_accuracy: 0.6292\n",
      "Epoch 29/30\n",
      "800/800 [==============================] - 0s 29us/step - loss: 0.6538 - accuracy: 0.6162 - val_loss: 0.6450 - val_accuracy: 0.6292\n",
      "Epoch 30/30\n",
      "800/800 [==============================] - 0s 27us/step - loss: 0.6534 - accuracy: 0.6162 - val_loss: 0.6445 - val_accuracy: 0.6292\n"
     ]
    }
   ],
   "source": [
    "model_3_history = model_2.fit(X, y, epochs=30, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Nodes to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_256 = Sequential()\n",
    "model_256.add(Dense(256,input_dim=8,activation='sigmoid'))\n",
    "model_256.add(Dropout(0.2))\n",
    "model_256.add(Dense(256,activation='sigmoid'))\n",
    "model_256.add(Dropout(0.2))\n",
    "model_256.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_256.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/60\n",
      "800/800 [==============================] - 0s 483us/step - loss: 0.6878 - accuracy: 0.5600 - val_loss: 0.6590 - val_accuracy: 0.6292\n",
      "Epoch 2/60\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.6815 - accuracy: 0.5763 - val_loss: 0.6551 - val_accuracy: 0.6292\n",
      "Epoch 3/60\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6760 - accuracy: 0.5763 - val_loss: 0.6505 - val_accuracy: 0.6292\n",
      "Epoch 4/60\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6838 - accuracy: 0.6025 - val_loss: 0.6476 - val_accuracy: 0.6292\n",
      "Epoch 5/60\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6692 - accuracy: 0.6162 - val_loss: 0.6442 - val_accuracy: 0.6292\n",
      "Epoch 6/60\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6794 - accuracy: 0.5975 - val_loss: 0.6413 - val_accuracy: 0.6292\n",
      "Epoch 7/60\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.6688 - accuracy: 0.6100 - val_loss: 0.6388 - val_accuracy: 0.6292\n",
      "Epoch 8/60\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6618 - accuracy: 0.6112 - val_loss: 0.6364 - val_accuracy: 0.6292\n",
      "Epoch 9/60\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6607 - accuracy: 0.6200 - val_loss: 0.6329 - val_accuracy: 0.6292\n",
      "Epoch 10/60\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6604 - accuracy: 0.6275 - val_loss: 0.6311 - val_accuracy: 0.6292\n",
      "Epoch 11/60\n",
      "800/800 [==============================] - 0s 72us/step - loss: 0.6617 - accuracy: 0.6125 - val_loss: 0.6284 - val_accuracy: 0.6292\n",
      "Epoch 12/60\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.6674 - accuracy: 0.5987 - val_loss: 0.6265 - val_accuracy: 0.6292\n",
      "Epoch 13/60\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.6515 - accuracy: 0.6350 - val_loss: 0.6245 - val_accuracy: 0.6292\n",
      "Epoch 14/60\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.6531 - accuracy: 0.6200 - val_loss: 0.6228 - val_accuracy: 0.6292\n",
      "Epoch 15/60\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6492 - accuracy: 0.6237 - val_loss: 0.6212 - val_accuracy: 0.6292\n",
      "Epoch 16/60\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6633 - accuracy: 0.6263 - val_loss: 0.6218 - val_accuracy: 0.6517\n",
      "Epoch 17/60\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6511 - accuracy: 0.6263 - val_loss: 0.6181 - val_accuracy: 0.6404\n",
      "Epoch 18/60\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6558 - accuracy: 0.6100 - val_loss: 0.6180 - val_accuracy: 0.6742\n",
      "Epoch 19/60\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.6404 - accuracy: 0.6237 - val_loss: 0.6164 - val_accuracy: 0.6629\n",
      "Epoch 20/60\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.6448 - accuracy: 0.6175 - val_loss: 0.6136 - val_accuracy: 0.6629\n",
      "Epoch 21/60\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6544 - accuracy: 0.6225 - val_loss: 0.6170 - val_accuracy: 0.6629\n",
      "Epoch 22/60\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6472 - accuracy: 0.6587 - val_loss: 0.6109 - val_accuracy: 0.6517\n",
      "Epoch 23/60\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.6398 - accuracy: 0.6587 - val_loss: 0.6102 - val_accuracy: 0.6742\n",
      "Epoch 24/60\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6486 - accuracy: 0.6313 - val_loss: 0.6084 - val_accuracy: 0.6517\n",
      "Epoch 25/60\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6361 - accuracy: 0.6600 - val_loss: 0.6077 - val_accuracy: 0.6742\n",
      "Epoch 26/60\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6328 - accuracy: 0.6562 - val_loss: 0.6090 - val_accuracy: 0.6629\n",
      "Epoch 27/60\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6397 - accuracy: 0.6500 - val_loss: 0.6052 - val_accuracy: 0.6629\n",
      "Epoch 28/60\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6328 - accuracy: 0.6500 - val_loss: 0.6043 - val_accuracy: 0.6629\n",
      "Epoch 29/60\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6308 - accuracy: 0.6562 - val_loss: 0.6039 - val_accuracy: 0.6629\n",
      "Epoch 30/60\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6331 - accuracy: 0.6600 - val_loss: 0.6030 - val_accuracy: 0.6517\n",
      "Epoch 31/60\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.6320 - accuracy: 0.6513 - val_loss: 0.6016 - val_accuracy: 0.6629\n",
      "Epoch 32/60\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.6378 - accuracy: 0.6513 - val_loss: 0.6012 - val_accuracy: 0.6629\n",
      "Epoch 33/60\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6331 - accuracy: 0.6625 - val_loss: 0.6002 - val_accuracy: 0.6517\n",
      "Epoch 34/60\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6266 - accuracy: 0.6513 - val_loss: 0.6001 - val_accuracy: 0.6629\n",
      "Epoch 35/60\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6393 - accuracy: 0.6413 - val_loss: 0.5987 - val_accuracy: 0.6629\n",
      "Epoch 36/60\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6343 - accuracy: 0.6625 - val_loss: 0.5978 - val_accuracy: 0.6629\n",
      "Epoch 37/60\n",
      "800/800 [==============================] - 0s 80us/step - loss: 0.6280 - accuracy: 0.6662 - val_loss: 0.5978 - val_accuracy: 0.6517\n",
      "Epoch 38/60\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6380 - accuracy: 0.6463 - val_loss: 0.5966 - val_accuracy: 0.6629\n",
      "Epoch 39/60\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6257 - accuracy: 0.6725 - val_loss: 0.5975 - val_accuracy: 0.6742\n",
      "Epoch 40/60\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6192 - accuracy: 0.6750 - val_loss: 0.5983 - val_accuracy: 0.6742\n",
      "Epoch 41/60\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6281 - accuracy: 0.6712 - val_loss: 0.5948 - val_accuracy: 0.6629\n",
      "Epoch 42/60\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6311 - accuracy: 0.6637 - val_loss: 0.5945 - val_accuracy: 0.6629\n",
      "Epoch 43/60\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6351 - accuracy: 0.6488 - val_loss: 0.5938 - val_accuracy: 0.6629\n",
      "Epoch 44/60\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6286 - accuracy: 0.6500 - val_loss: 0.5940 - val_accuracy: 0.6629\n",
      "Epoch 45/60\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6347 - accuracy: 0.6500 - val_loss: 0.5935 - val_accuracy: 0.6629\n",
      "Epoch 46/60\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6308 - accuracy: 0.6587 - val_loss: 0.5925 - val_accuracy: 0.6629\n",
      "Epoch 47/60\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6320 - accuracy: 0.6538 - val_loss: 0.5919 - val_accuracy: 0.6629\n",
      "Epoch 48/60\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6114 - accuracy: 0.6762 - val_loss: 0.5914 - val_accuracy: 0.6629\n",
      "Epoch 49/60\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6347 - accuracy: 0.6612 - val_loss: 0.5914 - val_accuracy: 0.6629\n",
      "Epoch 50/60\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6174 - accuracy: 0.6750 - val_loss: 0.5907 - val_accuracy: 0.6629\n",
      "Epoch 51/60\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.6191 - accuracy: 0.6662 - val_loss: 0.5910 - val_accuracy: 0.6742\n",
      "Epoch 52/60\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6272 - accuracy: 0.6500 - val_loss: 0.5902 - val_accuracy: 0.6742\n",
      "Epoch 53/60\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6233 - accuracy: 0.6550 - val_loss: 0.5893 - val_accuracy: 0.6629\n",
      "Epoch 54/60\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6326 - accuracy: 0.6687 - val_loss: 0.5895 - val_accuracy: 0.6742\n",
      "Epoch 55/60\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6331 - accuracy: 0.6538 - val_loss: 0.5885 - val_accuracy: 0.6742\n",
      "Epoch 56/60\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6225 - accuracy: 0.6762 - val_loss: 0.5893 - val_accuracy: 0.6854\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 57us/step - loss: 0.6223 - accuracy: 0.6675 - val_loss: 0.5877 - val_accuracy: 0.6629\n",
      "Epoch 58/60\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6164 - accuracy: 0.6850 - val_loss: 0.5911 - val_accuracy: 0.6742\n",
      "Epoch 59/60\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6203 - accuracy: 0.6562 - val_loss: 0.5869 - val_accuracy: 0.6629\n",
      "Epoch 60/60\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6225 - accuracy: 0.6625 - val_loss: 0.5878 - val_accuracy: 0.6629\n"
     ]
    }
   ],
   "source": [
    "model_256_history = model_256.fit(X, y, epochs=60, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model = Sequential()\n",
    "relu_model.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_model.add(Dropout(0.2))\n",
    "relu_model.add(Dense(256,activation='relu'))\n",
    "relu_model.add(Dropout(0.2))\n",
    "relu_model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 506us/step - loss: 1.6042 - accuracy: 0.5400 - val_loss: 1.0532 - val_accuracy: 0.6292\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 76us/step - loss: 1.1232 - accuracy: 0.5875 - val_loss: 0.5947 - val_accuracy: 0.6854\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.7815 - accuracy: 0.6413 - val_loss: 0.7768 - val_accuracy: 0.7303\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.8637 - accuracy: 0.6575 - val_loss: 1.2090 - val_accuracy: 0.6292\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.9138 - accuracy: 0.6288 - val_loss: 0.6889 - val_accuracy: 0.6966\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 55us/step - loss: 0.7430 - accuracy: 0.6475 - val_loss: 0.6916 - val_accuracy: 0.6292\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.7396 - accuracy: 0.6450 - val_loss: 0.5725 - val_accuracy: 0.6742\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7078 - accuracy: 0.6612 - val_loss: 0.5531 - val_accuracy: 0.7416\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.7170 - accuracy: 0.6475 - val_loss: 0.7420 - val_accuracy: 0.6292\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 93us/step - loss: 0.6800 - accuracy: 0.6513 - val_loss: 0.5616 - val_accuracy: 0.7191\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 104us/step - loss: 0.6851 - accuracy: 0.6400 - val_loss: 0.5518 - val_accuracy: 0.7528\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.7002 - accuracy: 0.6687 - val_loss: 0.5424 - val_accuracy: 0.7079\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6906 - accuracy: 0.6500 - val_loss: 0.5421 - val_accuracy: 0.6854\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.6558 - accuracy: 0.6625 - val_loss: 0.5669 - val_accuracy: 0.7416\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6583 - accuracy: 0.6637 - val_loss: 0.5400 - val_accuracy: 0.7079\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.6554 - accuracy: 0.6737 - val_loss: 0.5494 - val_accuracy: 0.7416\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.6574 - accuracy: 0.6550 - val_loss: 0.5625 - val_accuracy: 0.6854\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6528 - accuracy: 0.6538 - val_loss: 0.5767 - val_accuracy: 0.6292\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6639 - accuracy: 0.6488 - val_loss: 0.5386 - val_accuracy: 0.6966\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.6350 - accuracy: 0.6850 - val_loss: 0.5379 - val_accuracy: 0.6966\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6625 - accuracy: 0.6650 - val_loss: 0.5648 - val_accuracy: 0.6517\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.6492 - accuracy: 0.6625 - val_loss: 0.5499 - val_accuracy: 0.7303\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6287 - accuracy: 0.6650 - val_loss: 0.5336 - val_accuracy: 0.6966\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6433 - accuracy: 0.6825 - val_loss: 0.6723 - val_accuracy: 0.6292\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6714 - accuracy: 0.6488 - val_loss: 0.5486 - val_accuracy: 0.7416\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6272 - accuracy: 0.6762 - val_loss: 0.5649 - val_accuracy: 0.6292\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6274 - accuracy: 0.6750 - val_loss: 0.5331 - val_accuracy: 0.7079\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.6350 - accuracy: 0.6812 - val_loss: 0.5319 - val_accuracy: 0.7191\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6263 - accuracy: 0.6888 - val_loss: 0.5594 - val_accuracy: 0.6966\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.6196 - accuracy: 0.6837 - val_loss: 0.5360 - val_accuracy: 0.7303\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6508 - accuracy: 0.6475 - val_loss: 0.5465 - val_accuracy: 0.7416\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6185 - accuracy: 0.6675 - val_loss: 0.5430 - val_accuracy: 0.7303\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.6297 - accuracy: 0.6687 - val_loss: 0.5399 - val_accuracy: 0.7416\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.6386 - accuracy: 0.6575 - val_loss: 0.5554 - val_accuracy: 0.6966\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6203 - accuracy: 0.6812 - val_loss: 0.5697 - val_accuracy: 0.6292\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6325 - accuracy: 0.6650 - val_loss: 0.5533 - val_accuracy: 0.7079\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6104 - accuracy: 0.6850 - val_loss: 0.5443 - val_accuracy: 0.7303\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 162us/step - loss: 0.6508 - accuracy: 0.6575 - val_loss: 0.5389 - val_accuracy: 0.7191\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 79us/step - loss: 0.6257 - accuracy: 0.6775 - val_loss: 0.5364 - val_accuracy: 0.7079\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6133 - accuracy: 0.6812 - val_loss: 0.5447 - val_accuracy: 0.7303\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6172 - accuracy: 0.6687 - val_loss: 0.5414 - val_accuracy: 0.7303\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6160 - accuracy: 0.6700 - val_loss: 0.5362 - val_accuracy: 0.7191\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6144 - accuracy: 0.6812 - val_loss: 0.5398 - val_accuracy: 0.7191\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6242 - accuracy: 0.6675 - val_loss: 0.5408 - val_accuracy: 0.7191\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6143 - accuracy: 0.6850 - val_loss: 0.5389 - val_accuracy: 0.7528\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6056 - accuracy: 0.6988 - val_loss: 0.5700 - val_accuracy: 0.6292\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 43us/step - loss: 0.6128 - accuracy: 0.6637 - val_loss: 0.5278 - val_accuracy: 0.7079\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6118 - accuracy: 0.6950 - val_loss: 0.5388 - val_accuracy: 0.7191\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6136 - accuracy: 0.7000 - val_loss: 0.5431 - val_accuracy: 0.7191\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6086 - accuracy: 0.6938 - val_loss: 0.5462 - val_accuracy: 0.7079\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 90us/step - loss: 0.6095 - accuracy: 0.6750 - val_loss: 0.5387 - val_accuracy: 0.7640\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.6157 - accuracy: 0.6750 - val_loss: 0.5306 - val_accuracy: 0.7528\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6114 - accuracy: 0.6875 - val_loss: 0.5250 - val_accuracy: 0.7191\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6161 - accuracy: 0.6950 - val_loss: 0.5296 - val_accuracy: 0.7416\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.6118 - accuracy: 0.6975 - val_loss: 0.5338 - val_accuracy: 0.7416\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6008 - accuracy: 0.6888 - val_loss: 0.5306 - val_accuracy: 0.7528\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 48us/step - loss: 0.5978 - accuracy: 0.6850 - val_loss: 0.5396 - val_accuracy: 0.7416\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 41us/step - loss: 0.6127 - accuracy: 0.6900 - val_loss: 0.5660 - val_accuracy: 0.6292\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.6221 - accuracy: 0.6750 - val_loss: 0.5412 - val_accuracy: 0.7416\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.6067 - accuracy: 0.6900 - val_loss: 0.5458 - val_accuracy: 0.7079\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6138 - accuracy: 0.6900 - val_loss: 0.5351 - val_accuracy: 0.7416\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6083 - accuracy: 0.6925 - val_loss: 0.5412 - val_accuracy: 0.7416\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6114 - accuracy: 0.6950 - val_loss: 0.5499 - val_accuracy: 0.7079\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 88us/step - loss: 0.6146 - accuracy: 0.6775 - val_loss: 0.5351 - val_accuracy: 0.7528\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 71us/step - loss: 0.6131 - accuracy: 0.6862 - val_loss: 0.5319 - val_accuracy: 0.7416\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5970 - accuracy: 0.7075 - val_loss: 0.5371 - val_accuracy: 0.7079\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 67us/step - loss: 0.6099 - accuracy: 0.6700 - val_loss: 0.5372 - val_accuracy: 0.7079\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6179 - accuracy: 0.6913 - val_loss: 0.5283 - val_accuracy: 0.7753\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.6210 - accuracy: 0.6862 - val_loss: 0.5305 - val_accuracy: 0.7753\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.6030 - accuracy: 0.6900 - val_loss: 0.5356 - val_accuracy: 0.7416\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6138 - accuracy: 0.6800 - val_loss: 0.5265 - val_accuracy: 0.7753\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 77us/step - loss: 0.6031 - accuracy: 0.6975 - val_loss: 0.5335 - val_accuracy: 0.7416\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.5960 - accuracy: 0.6862 - val_loss: 0.5351 - val_accuracy: 0.7303\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.6060 - accuracy: 0.6925 - val_loss: 0.5276 - val_accuracy: 0.7640\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.6109 - accuracy: 0.6825 - val_loss: 0.5337 - val_accuracy: 0.7416\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6144 - accuracy: 0.6938 - val_loss: 0.5416 - val_accuracy: 0.7416\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.6016 - accuracy: 0.7025 - val_loss: 0.5295 - val_accuracy: 0.7528\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 83us/step - loss: 0.6011 - accuracy: 0.6913 - val_loss: 0.5367 - val_accuracy: 0.7191\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.5941 - accuracy: 0.7038 - val_loss: 0.5412 - val_accuracy: 0.7079\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.5946 - accuracy: 0.6888 - val_loss: 0.5541 - val_accuracy: 0.6517\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.6183 - accuracy: 0.6662 - val_loss: 0.5341 - val_accuracy: 0.7303\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.6016 - accuracy: 0.6975 - val_loss: 0.5391 - val_accuracy: 0.7303\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.5973 - accuracy: 0.6925 - val_loss: 0.5387 - val_accuracy: 0.7303\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.6043 - accuracy: 0.6900 - val_loss: 0.5366 - val_accuracy: 0.7303\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 42us/step - loss: 0.6069 - accuracy: 0.7013 - val_loss: 0.5355 - val_accuracy: 0.7528\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.6048 - accuracy: 0.6712 - val_loss: 0.5379 - val_accuracy: 0.7416\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6003 - accuracy: 0.6875 - val_loss: 0.5341 - val_accuracy: 0.7303\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6101 - accuracy: 0.6687 - val_loss: 0.5359 - val_accuracy: 0.7640\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6090 - accuracy: 0.6825 - val_loss: 0.5291 - val_accuracy: 0.7528\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.6057 - accuracy: 0.6963 - val_loss: 0.5319 - val_accuracy: 0.7416\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5997 - accuracy: 0.6837 - val_loss: 0.5318 - val_accuracy: 0.7416\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.6030 - accuracy: 0.6850 - val_loss: 0.5256 - val_accuracy: 0.7640\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 87us/step - loss: 0.6064 - accuracy: 0.6862 - val_loss: 0.5246 - val_accuracy: 0.7303\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6024 - accuracy: 0.7013 - val_loss: 0.5247 - val_accuracy: 0.7191\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 75us/step - loss: 0.5903 - accuracy: 0.6812 - val_loss: 0.5185 - val_accuracy: 0.7416\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.6038 - accuracy: 0.6812 - val_loss: 0.5305 - val_accuracy: 0.7416\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5970 - accuracy: 0.7013 - val_loss: 0.5234 - val_accuracy: 0.7640\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.6087 - accuracy: 0.6712 - val_loss: 0.5269 - val_accuracy: 0.7528\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.5876 - accuracy: 0.6812 - val_loss: 0.5264 - val_accuracy: 0.7303\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.5975 - accuracy: 0.6913 - val_loss: 0.5316 - val_accuracy: 0.7640\n"
     ]
    }
   ],
   "source": [
    "relu_model_history = relu_model.fit(X, y, epochs=100, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model = Sequential()\n",
    "relu_adam_model.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_adam_model.add(Dropout(0.2))\n",
    "relu_adam_model.add(Dense(256,activation='relu'))\n",
    "relu_adam_model.add(Dropout(0.2))\n",
    "relu_adam_model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 0s 577us/step - loss: 1.7829 - accuracy: 0.5825 - val_loss: 0.7699 - val_accuracy: 0.6966\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 1.2652 - accuracy: 0.6150 - val_loss: 0.6754 - val_accuracy: 0.6742\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.9603 - accuracy: 0.6200 - val_loss: 0.5666 - val_accuracy: 0.6854\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.9812 - accuracy: 0.5475 - val_loss: 0.5924 - val_accuracy: 0.6854\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.8205 - accuracy: 0.6675 - val_loss: 0.5446 - val_accuracy: 0.6854\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.9036 - accuracy: 0.6525 - val_loss: 0.5676 - val_accuracy: 0.7303\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.7975 - accuracy: 0.6375 - val_loss: 0.5570 - val_accuracy: 0.7079\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.7782 - accuracy: 0.6300 - val_loss: 0.5446 - val_accuracy: 0.7303\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.7204 - accuracy: 0.6762 - val_loss: 0.5180 - val_accuracy: 0.7079\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 0s 59us/step - loss: 0.7172 - accuracy: 0.6562 - val_loss: 0.5088 - val_accuracy: 0.7191\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.7477 - accuracy: 0.6413 - val_loss: 0.4973 - val_accuracy: 0.7303\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.7049 - accuracy: 0.6700 - val_loss: 0.5078 - val_accuracy: 0.7303\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.7169 - accuracy: 0.6800 - val_loss: 0.5632 - val_accuracy: 0.6404\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.7275 - accuracy: 0.6463 - val_loss: 0.5159 - val_accuracy: 0.7528\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 0s 66us/step - loss: 0.7029 - accuracy: 0.6687 - val_loss: 0.5155 - val_accuracy: 0.7528\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.6768 - accuracy: 0.6725 - val_loss: 0.5066 - val_accuracy: 0.7416\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.6540 - accuracy: 0.6913 - val_loss: 0.4868 - val_accuracy: 0.7753\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.6547 - accuracy: 0.6800 - val_loss: 0.5118 - val_accuracy: 0.7416\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 0s 57us/step - loss: 0.6472 - accuracy: 0.6737 - val_loss: 0.5063 - val_accuracy: 0.7640\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6429 - accuracy: 0.6762 - val_loss: 0.5070 - val_accuracy: 0.7640\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.5957 - accuracy: 0.7025 - val_loss: 0.5288 - val_accuracy: 0.7191\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.6493 - accuracy: 0.6825 - val_loss: 0.5007 - val_accuracy: 0.7528\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 0s 60us/step - loss: 0.5979 - accuracy: 0.6938 - val_loss: 0.4956 - val_accuracy: 0.7416\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.6507 - accuracy: 0.6900 - val_loss: 0.4734 - val_accuracy: 0.7640\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 0s 63us/step - loss: 0.5889 - accuracy: 0.7000 - val_loss: 0.5041 - val_accuracy: 0.7528\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5953 - accuracy: 0.6938 - val_loss: 0.4783 - val_accuracy: 0.7865\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.5923 - accuracy: 0.6950 - val_loss: 0.4881 - val_accuracy: 0.7416\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.6131 - accuracy: 0.7075 - val_loss: 0.4626 - val_accuracy: 0.7865\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 0s 65us/step - loss: 0.5798 - accuracy: 0.7050 - val_loss: 0.5044 - val_accuracy: 0.7303\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 0s 68us/step - loss: 0.6134 - accuracy: 0.6975 - val_loss: 0.4620 - val_accuracy: 0.8090\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 0s 62us/step - loss: 0.5895 - accuracy: 0.6925 - val_loss: 0.4587 - val_accuracy: 0.7753\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.5804 - accuracy: 0.7287 - val_loss: 0.4498 - val_accuracy: 0.7978\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 0s 61us/step - loss: 0.5628 - accuracy: 0.7125 - val_loss: 0.4535 - val_accuracy: 0.7865\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 0s 73us/step - loss: 0.5654 - accuracy: 0.7250 - val_loss: 0.4578 - val_accuracy: 0.7978\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 0s 74us/step - loss: 0.5434 - accuracy: 0.7437 - val_loss: 0.4571 - val_accuracy: 0.7753\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 0s 64us/step - loss: 0.5608 - accuracy: 0.7300 - val_loss: 0.4420 - val_accuracy: 0.8202\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 0s 70us/step - loss: 0.5571 - accuracy: 0.7375 - val_loss: 0.4450 - val_accuracy: 0.7865\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.5550 - accuracy: 0.7312 - val_loss: 0.4413 - val_accuracy: 0.8090\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5426 - accuracy: 0.7487 - val_loss: 0.4239 - val_accuracy: 0.8090\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5462 - accuracy: 0.7275 - val_loss: 0.4245 - val_accuracy: 0.8427\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.5491 - accuracy: 0.7575 - val_loss: 0.4288 - val_accuracy: 0.7865\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.5548 - accuracy: 0.7387 - val_loss: 0.4374 - val_accuracy: 0.8315\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.5637 - accuracy: 0.7563 - val_loss: 0.4228 - val_accuracy: 0.7865\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.5360 - accuracy: 0.7487 - val_loss: 0.4282 - val_accuracy: 0.8315\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.5452 - accuracy: 0.7663 - val_loss: 0.4183 - val_accuracy: 0.8202\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5345 - accuracy: 0.7387 - val_loss: 0.4270 - val_accuracy: 0.8090\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.5327 - accuracy: 0.7538 - val_loss: 0.4252 - val_accuracy: 0.8202\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5260 - accuracy: 0.7600 - val_loss: 0.4339 - val_accuracy: 0.8427\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.5487 - accuracy: 0.7513 - val_loss: 0.4277 - val_accuracy: 0.8202\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.5226 - accuracy: 0.7462 - val_loss: 0.4174 - val_accuracy: 0.8315\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5221 - accuracy: 0.7600 - val_loss: 0.4099 - val_accuracy: 0.8090\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.5291 - accuracy: 0.7663 - val_loss: 0.4124 - val_accuracy: 0.8202\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.5217 - accuracy: 0.7550 - val_loss: 0.4084 - val_accuracy: 0.8202\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.5192 - accuracy: 0.7650 - val_loss: 0.4097 - val_accuracy: 0.8315\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5214 - accuracy: 0.7525 - val_loss: 0.4131 - val_accuracy: 0.8202\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5182 - accuracy: 0.7850 - val_loss: 0.4072 - val_accuracy: 0.8427\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 53us/step - loss: 0.5292 - accuracy: 0.7638 - val_loss: 0.4117 - val_accuracy: 0.8202\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.5419 - accuracy: 0.7650 - val_loss: 0.4050 - val_accuracy: 0.8315\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.5211 - accuracy: 0.7675 - val_loss: 0.4017 - val_accuracy: 0.8315\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.4981 - accuracy: 0.7725 - val_loss: 0.4199 - val_accuracy: 0.8315\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.5288 - accuracy: 0.7538 - val_loss: 0.4018 - val_accuracy: 0.8202\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.5258 - accuracy: 0.7688 - val_loss: 0.4008 - val_accuracy: 0.8315\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4955 - accuracy: 0.7625 - val_loss: 0.4210 - val_accuracy: 0.8427\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.5028 - accuracy: 0.7625 - val_loss: 0.4152 - val_accuracy: 0.8427\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4910 - accuracy: 0.7887 - val_loss: 0.4041 - val_accuracy: 0.8427\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4954 - accuracy: 0.7837 - val_loss: 0.4016 - val_accuracy: 0.8202\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.5024 - accuracy: 0.7763 - val_loss: 0.4080 - val_accuracy: 0.8315\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4875 - accuracy: 0.7850 - val_loss: 0.3988 - val_accuracy: 0.8315\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4972 - accuracy: 0.7862 - val_loss: 0.4069 - val_accuracy: 0.8315\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 0s 47us/step - loss: 0.4867 - accuracy: 0.7925 - val_loss: 0.3941 - val_accuracy: 0.8427\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4785 - accuracy: 0.7788 - val_loss: 0.3894 - val_accuracy: 0.8202\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4917 - accuracy: 0.7825 - val_loss: 0.3893 - val_accuracy: 0.8315\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.5024 - accuracy: 0.7725 - val_loss: 0.3926 - val_accuracy: 0.8202\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 0s 44us/step - loss: 0.4931 - accuracy: 0.7800 - val_loss: 0.3926 - val_accuracy: 0.8427\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 0s 45us/step - loss: 0.5015 - accuracy: 0.7825 - val_loss: 0.4001 - val_accuracy: 0.8315\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4781 - accuracy: 0.7975 - val_loss: 0.3883 - val_accuracy: 0.8539\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4770 - accuracy: 0.8000 - val_loss: 0.3981 - val_accuracy: 0.8315\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 0s 53us/step - loss: 0.4961 - accuracy: 0.7925 - val_loss: 0.3813 - val_accuracy: 0.8315\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4810 - accuracy: 0.7925 - val_loss: 0.3832 - val_accuracy: 0.8427\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 0s 58us/step - loss: 0.4687 - accuracy: 0.7975 - val_loss: 0.3824 - val_accuracy: 0.8315\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4889 - accuracy: 0.7763 - val_loss: 0.3855 - val_accuracy: 0.8427\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4817 - accuracy: 0.7975 - val_loss: 0.3846 - val_accuracy: 0.8427\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4818 - accuracy: 0.8087 - val_loss: 0.3828 - val_accuracy: 0.8427\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.4719 - accuracy: 0.7875 - val_loss: 0.3804 - val_accuracy: 0.8427\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 0s 46us/step - loss: 0.4707 - accuracy: 0.8012 - val_loss: 0.3786 - val_accuracy: 0.8315\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4598 - accuracy: 0.8087 - val_loss: 0.3742 - val_accuracy: 0.8427\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4746 - accuracy: 0.7900 - val_loss: 0.3744 - val_accuracy: 0.8427\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4657 - accuracy: 0.8025 - val_loss: 0.3782 - val_accuracy: 0.8427\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 0s 69us/step - loss: 0.4729 - accuracy: 0.8037 - val_loss: 0.3683 - val_accuracy: 0.8427\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4587 - accuracy: 0.8062 - val_loss: 0.3790 - val_accuracy: 0.8315\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 0s 48us/step - loss: 0.4761 - accuracy: 0.7887 - val_loss: 0.3816 - val_accuracy: 0.8315\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4711 - accuracy: 0.7862 - val_loss: 0.3718 - val_accuracy: 0.8315\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4911 - accuracy: 0.7850 - val_loss: 0.3886 - val_accuracy: 0.8427\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 0s 54us/step - loss: 0.4729 - accuracy: 0.7975 - val_loss: 0.3866 - val_accuracy: 0.8427\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4879 - accuracy: 0.7825 - val_loss: 0.3770 - val_accuracy: 0.8315\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 0s 52us/step - loss: 0.4713 - accuracy: 0.8163 - val_loss: 0.3771 - val_accuracy: 0.8315\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 0s 50us/step - loss: 0.4684 - accuracy: 0.8000 - val_loss: 0.3767 - val_accuracy: 0.8315\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 0s 56us/step - loss: 0.4674 - accuracy: 0.7987 - val_loss: 0.3820 - val_accuracy: 0.8427\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 0s 49us/step - loss: 0.4613 - accuracy: 0.7912 - val_loss: 0.3746 - val_accuracy: 0.8427\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 0s 51us/step - loss: 0.4529 - accuracy: 0.7987 - val_loss: 0.3740 - val_accuracy: 0.8427\n"
     ]
    }
   ],
   "source": [
    "relu_adam_model_history = relu_adam_model.fit(X, y, epochs=100, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(relu_adam_model_history.history['accuracy'])\n",
    "plt.plot(relu_adam_model_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Accuracy so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_01 = Sequential()\n",
    "relu_adam_model_01.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_adam_model_01.add(Dropout(0.2))\n",
    "relu_adam_model_01.add(Dense(256,activation='relu'))\n",
    "relu_adam_model_01.add(Dropout(0.2))\n",
    "relu_adam_model_01.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_01.compile(optimizer=adam,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 89 samples\n",
      "Epoch 1/50\n",
      "800/800 [==============================] - 0s 606us/step - loss: 8.6617 - accuracy: 0.4000 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 2/50\n",
      "800/800 [==============================] - 0s 62us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 3/50\n",
      "800/800 [==============================] - 0s 66us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 4/50\n",
      "800/800 [==============================] - 0s 76us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 5/50\n",
      "800/800 [==============================] - 0s 60us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 6/50\n",
      "800/800 [==============================] - 0s 89us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 7/50\n",
      "800/800 [==============================] - 0s 59us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 8/50\n",
      "800/800 [==============================] - 0s 61us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 9/50\n",
      "800/800 [==============================] - 0s 62us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 10/50\n",
      "800/800 [==============================] - 0s 58us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 11/50\n",
      "800/800 [==============================] - 0s 56us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 12/50\n",
      "800/800 [==============================] - 0s 53us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 13/50\n",
      "800/800 [==============================] - 0s 66us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 14/50\n",
      "800/800 [==============================] - 0s 56us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 15/50\n",
      "800/800 [==============================] - 0s 69us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 16/50\n",
      "800/800 [==============================] - 0s 65us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 17/50\n",
      "800/800 [==============================] - 0s 64us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 18/50\n",
      "800/800 [==============================] - 0s 58us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 19/50\n",
      "800/800 [==============================] - 0s 68us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 20/50\n",
      "800/800 [==============================] - 0s 60us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 21/50\n",
      "800/800 [==============================] - 0s 61us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 22/50\n",
      "800/800 [==============================] - 0s 70us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 23/50\n",
      "800/800 [==============================] - 0s 65us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 24/50\n",
      "800/800 [==============================] - 0s 61us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 25/50\n",
      "800/800 [==============================] - 0s 57us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 26/50\n",
      "800/800 [==============================] - 0s 59us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 27/50\n",
      "800/800 [==============================] - 0s 66us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 28/50\n",
      "800/800 [==============================] - 0s 66us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 29/50\n",
      "800/800 [==============================] - 0s 58us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 30/50\n",
      "800/800 [==============================] - 0s 57us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 31/50\n",
      "800/800 [==============================] - 0s 68us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 32/50\n",
      "800/800 [==============================] - 0s 82us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 33/50\n",
      "800/800 [==============================] - 0s 60us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 34/50\n",
      "800/800 [==============================] - 0s 56us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 35/50\n",
      "800/800 [==============================] - 0s 83us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 36/50\n",
      "800/800 [==============================] - 0s 72us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 37/50\n",
      "800/800 [==============================] - 0s 79us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 38/50\n",
      "800/800 [==============================] - 0s 56us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 39/50\n",
      "800/800 [==============================] - 0s 51us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 40/50\n",
      "800/800 [==============================] - 0s 51us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 41/50\n",
      "800/800 [==============================] - 0s 82us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 42/50\n",
      "800/800 [==============================] - 0s 82us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 43/50\n",
      "800/800 [==============================] - 0s 55us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 44/50\n",
      "800/800 [==============================] - 0s 54us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 45/50\n",
      "800/800 [==============================] - 0s 67us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 46/50\n",
      "800/800 [==============================] - 0s 55us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 47/50\n",
      "800/800 [==============================] - 0s 53us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 48/50\n",
      "800/800 [==============================] - 0s 55us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 49/50\n",
      "800/800 [==============================] - 0s 64us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n",
      "Epoch 50/50\n",
      "800/800 [==============================] - 0s 59us/step - loss: 9.8245 - accuracy: 0.3837 - val_loss: 10.0312 - val_accuracy: 0.3708\n"
     ]
    }
   ],
   "source": [
    "relu_adam_model_01_history = relu_adam_model_01.fit(X, y, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(relu_adam_model_01_history.history['accuracy'])\n",
    "plt.plot(relu_adam_model_01_history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../titanic/cleaned_test.csv')\n",
    "passengerID = test_data['PassengerId']\n",
    "test_data.drop('PassengerId',axis = 1 , inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07849133],\n",
       "       [0.36766016],\n",
       "       [0.03995687],\n",
       "       [0.08047646],\n",
       "       [0.52793974],\n",
       "       [0.16978014],\n",
       "       [0.6490154 ],\n",
       "       [0.1668283 ],\n",
       "       [0.59249413],\n",
       "       [0.16054988],\n",
       "       [0.08536673],\n",
       "       [0.2000078 ],\n",
       "       [0.8181751 ],\n",
       "       [0.12847298],\n",
       "       [0.9095223 ],\n",
       "       [0.7374113 ],\n",
       "       [0.12281796],\n",
       "       [0.10238194],\n",
       "       [0.5020225 ],\n",
       "       [0.40982693],\n",
       "       [0.35036844],\n",
       "       [0.21680632],\n",
       "       [0.84160495],\n",
       "       [0.4215545 ],\n",
       "       [0.88627756],\n",
       "       [0.06082708],\n",
       "       [0.79744446],\n",
       "       [0.09474477],\n",
       "       [0.27689743],\n",
       "       [0.15171373],\n",
       "       [0.12745422],\n",
       "       [0.16968021],\n",
       "       [0.52505136],\n",
       "       [0.53146267],\n",
       "       [0.33623034],\n",
       "       [0.11863855],\n",
       "       [0.62577164],\n",
       "       [0.6494806 ],\n",
       "       [0.08654496],\n",
       "       [0.49653992],\n",
       "       [0.06234556],\n",
       "       [0.23607925],\n",
       "       [0.06307244],\n",
       "       [0.7342757 ],\n",
       "       [0.8872632 ],\n",
       "       [0.08292821],\n",
       "       [0.21899468],\n",
       "       [0.09537107],\n",
       "       [0.94257843],\n",
       "       [0.57014453],\n",
       "       [0.37969625],\n",
       "       [0.13338974],\n",
       "       [0.5056673 ],\n",
       "       [0.8834001 ],\n",
       "       [0.12780371],\n",
       "       [0.05660117],\n",
       "       [0.06720504],\n",
       "       [0.08246255],\n",
       "       [0.13157976],\n",
       "       [0.9278967 ],\n",
       "       [0.12192956],\n",
       "       [0.10824782],\n",
       "       [0.11193898],\n",
       "       [0.6933036 ],\n",
       "       [0.88737935],\n",
       "       [0.7945252 ],\n",
       "       [0.7096658 ],\n",
       "       [0.351659  ],\n",
       "       [0.2429145 ],\n",
       "       [0.9107355 ],\n",
       "       [0.6835648 ],\n",
       "       [0.09492853],\n",
       "       [0.6014334 ],\n",
       "       [0.24297434],\n",
       "       [0.905082  ],\n",
       "       [0.73718107],\n",
       "       [0.08568245],\n",
       "       [0.70626706],\n",
       "       [0.10800394],\n",
       "       [0.6835648 ],\n",
       "       [0.47270572],\n",
       "       [0.87920845],\n",
       "       [0.20048162],\n",
       "       [0.08536673],\n",
       "       [0.11648917],\n",
       "       [0.13202375],\n",
       "       [0.66994363],\n",
       "       [0.63911194],\n",
       "       [0.6835648 ],\n",
       "       [0.67198265],\n",
       "       [0.62226945],\n",
       "       [0.08513269],\n",
       "       [0.7174326 ],\n",
       "       [0.08568245],\n",
       "       [0.2459515 ],\n",
       "       [0.08270913],\n",
       "       [0.9382678 ],\n",
       "       [0.07549497],\n",
       "       [0.63438493],\n",
       "       [0.07000744],\n",
       "       [0.87233967],\n",
       "       [0.19250157],\n",
       "       [0.09537107],\n",
       "       [0.08074552],\n",
       "       [0.46518895],\n",
       "       [0.18310931],\n",
       "       [0.10679084],\n",
       "       [0.09537107],\n",
       "       [0.08712026],\n",
       "       [0.16676793],\n",
       "       [0.10489085],\n",
       "       [0.6843249 ],\n",
       "       [0.8017068 ],\n",
       "       [0.69679236],\n",
       "       [0.96914023],\n",
       "       [0.1830908 ],\n",
       "       [0.0876621 ],\n",
       "       [0.8692118 ],\n",
       "       [0.5390549 ],\n",
       "       [0.76463556],\n",
       "       [0.7630233 ],\n",
       "       [0.08361542],\n",
       "       [0.8589101 ],\n",
       "       [0.07604229],\n",
       "       [0.09537107],\n",
       "       [0.6637003 ],\n",
       "       [0.09087393],\n",
       "       [0.6425542 ],\n",
       "       [0.09656537],\n",
       "       [0.08568245],\n",
       "       [0.07142407],\n",
       "       [0.19460434],\n",
       "       [0.46236196],\n",
       "       [0.078376  ],\n",
       "       [0.06239447],\n",
       "       [0.08528608],\n",
       "       [0.08295345],\n",
       "       [0.11449388],\n",
       "       [0.6295494 ],\n",
       "       [0.06451812],\n",
       "       [0.11784083],\n",
       "       [0.9020543 ],\n",
       "       [0.73425484],\n",
       "       [0.23216254],\n",
       "       [0.20977041],\n",
       "       [0.08047587],\n",
       "       [0.45776787],\n",
       "       [0.09155667],\n",
       "       [0.23607925],\n",
       "       [0.14965877],\n",
       "       [0.8109386 ],\n",
       "       [0.09205586],\n",
       "       [0.4831608 ],\n",
       "       [0.05651081],\n",
       "       [0.08469832],\n",
       "       [0.9292133 ],\n",
       "       [0.6247176 ],\n",
       "       [0.20977041],\n",
       "       [0.5590653 ],\n",
       "       [0.6831296 ],\n",
       "       [0.41882116],\n",
       "       [0.739279  ],\n",
       "       [0.08388472],\n",
       "       [0.0972631 ],\n",
       "       [0.61722994],\n",
       "       [0.36779267],\n",
       "       [0.15879983],\n",
       "       [0.7835542 ],\n",
       "       [0.653893  ],\n",
       "       [0.08469832],\n",
       "       [0.08170697],\n",
       "       [0.12244064],\n",
       "       [0.09000286],\n",
       "       [0.06001288],\n",
       "       [0.73771936],\n",
       "       [0.8470758 ],\n",
       "       [0.3198948 ],\n",
       "       [0.66523075],\n",
       "       [0.9092091 ],\n",
       "       [0.10800394],\n",
       "       [0.37588802],\n",
       "       [0.7751265 ],\n",
       "       [0.09537107],\n",
       "       [0.91985875],\n",
       "       [0.11804634],\n",
       "       [0.73520476],\n",
       "       [0.10574237],\n",
       "       [0.02068636],\n",
       "       [0.09772855],\n",
       "       [0.17845589],\n",
       "       [0.22616309],\n",
       "       [0.24087578],\n",
       "       [0.06620377],\n",
       "       [0.6290304 ],\n",
       "       [0.06956849],\n",
       "       [0.8253371 ],\n",
       "       [0.63532114],\n",
       "       [0.11289361],\n",
       "       [0.6273149 ],\n",
       "       [0.7631019 ],\n",
       "       [0.8933712 ],\n",
       "       [0.7488882 ],\n",
       "       [0.6771252 ],\n",
       "       [0.1061801 ],\n",
       "       [0.21487755],\n",
       "       [0.6110314 ],\n",
       "       [0.10903969],\n",
       "       [0.7842382 ],\n",
       "       [0.08287859],\n",
       "       [0.15185687],\n",
       "       [0.08395365],\n",
       "       [0.5337416 ],\n",
       "       [0.74220407],\n",
       "       [0.12419283],\n",
       "       [0.35052896],\n",
       "       [0.68692064],\n",
       "       [0.75318086],\n",
       "       [0.91105455],\n",
       "       [0.08568245],\n",
       "       [0.6322885 ],\n",
       "       [0.0954873 ],\n",
       "       [0.71478677],\n",
       "       [0.0945707 ],\n",
       "       [0.7926527 ],\n",
       "       [0.5214259 ],\n",
       "       [0.08793852],\n",
       "       [0.6835648 ],\n",
       "       [0.09044665],\n",
       "       [0.10045296],\n",
       "       [0.5497899 ],\n",
       "       [0.83486235],\n",
       "       [0.0854376 ],\n",
       "       [0.09586611],\n",
       "       [0.41200066],\n",
       "       [0.09918204],\n",
       "       [0.48724544],\n",
       "       [0.10861063],\n",
       "       [0.585765  ],\n",
       "       [0.92380285],\n",
       "       [0.7924901 ],\n",
       "       [0.6989057 ],\n",
       "       [0.5884837 ],\n",
       "       [0.08535063],\n",
       "       [0.14320555],\n",
       "       [0.35391986],\n",
       "       [0.7950867 ],\n",
       "       [0.15675229],\n",
       "       [0.76463556],\n",
       "       [0.5819584 ],\n",
       "       [0.8418516 ],\n",
       "       [0.09955347],\n",
       "       [0.5378985 ],\n",
       "       [0.08917305],\n",
       "       [0.07392937],\n",
       "       [0.08469832],\n",
       "       [0.09537107],\n",
       "       [0.07736722],\n",
       "       [0.7470129 ],\n",
       "       [0.09450123],\n",
       "       [0.08338982],\n",
       "       [0.09477845],\n",
       "       [0.65233207],\n",
       "       [0.867496  ],\n",
       "       [0.11052579],\n",
       "       [0.08536673],\n",
       "       [0.0354481 ],\n",
       "       [0.08469832],\n",
       "       [0.62577164],\n",
       "       [0.13007522],\n",
       "       [0.56690496],\n",
       "       [0.09537107],\n",
       "       [0.8114463 ],\n",
       "       [0.6957683 ],\n",
       "       [0.08999029],\n",
       "       [0.7609346 ],\n",
       "       [0.09877089],\n",
       "       [0.14224088],\n",
       "       [0.14165664],\n",
       "       [0.11753878],\n",
       "       [0.64488876],\n",
       "       [0.80745506],\n",
       "       [0.6835648 ],\n",
       "       [0.5532532 ],\n",
       "       [0.8434391 ],\n",
       "       [0.06444976],\n",
       "       [0.08422992],\n",
       "       [0.46812865],\n",
       "       [0.09000286],\n",
       "       [0.08568245],\n",
       "       [0.3335426 ],\n",
       "       [0.6270364 ],\n",
       "       [0.09000286],\n",
       "       [0.45718342],\n",
       "       [0.07011029],\n",
       "       [0.08094823],\n",
       "       [0.8114192 ],\n",
       "       [0.15171373],\n",
       "       [0.41376102],\n",
       "       [0.07536608],\n",
       "       [0.0707967 ],\n",
       "       [0.12455696],\n",
       "       [0.10078356],\n",
       "       [0.08699778],\n",
       "       [0.6835648 ],\n",
       "       [0.68705   ],\n",
       "       [0.5212709 ],\n",
       "       [0.8572973 ],\n",
       "       [0.5254    ],\n",
       "       [0.5841626 ],\n",
       "       [0.12050903],\n",
       "       [0.09705323],\n",
       "       [0.08474648],\n",
       "       [0.5895376 ],\n",
       "       [0.95786357],\n",
       "       [0.7090389 ],\n",
       "       [0.72999907],\n",
       "       [0.13816148],\n",
       "       [0.07895318],\n",
       "       [0.1726006 ],\n",
       "       [0.08074552],\n",
       "       [0.08705077],\n",
       "       [0.11449388],\n",
       "       [0.25832617],\n",
       "       [0.92529845],\n",
       "       [0.08663839],\n",
       "       [0.50818044],\n",
       "       [0.593685  ],\n",
       "       [0.18984553],\n",
       "       [0.14438105],\n",
       "       [0.72936344],\n",
       "       [0.24599689],\n",
       "       [0.08999029],\n",
       "       [0.5092615 ],\n",
       "       [0.07903099],\n",
       "       [0.25357068],\n",
       "       [0.10523114],\n",
       "       [0.03741479],\n",
       "       [0.29582992],\n",
       "       [0.09000286],\n",
       "       [0.14546183],\n",
       "       [0.07035315],\n",
       "       [0.31698075],\n",
       "       [0.9916898 ],\n",
       "       [0.11018267],\n",
       "       [0.63172036],\n",
       "       [0.11449388],\n",
       "       [0.4810208 ],\n",
       "       [0.1278522 ],\n",
       "       [0.7965858 ],\n",
       "       [0.8879732 ],\n",
       "       [0.1061801 ],\n",
       "       [0.536165  ],\n",
       "       [0.22805902],\n",
       "       [0.9020244 ],\n",
       "       [0.20061752],\n",
       "       [0.8388323 ],\n",
       "       [0.08533454],\n",
       "       [0.09537107],\n",
       "       [0.6362667 ],\n",
       "       [0.00818259],\n",
       "       [0.70882726],\n",
       "       [0.7965858 ],\n",
       "       [0.08047646],\n",
       "       [0.80056524],\n",
       "       [0.54839826],\n",
       "       [0.13205543],\n",
       "       [0.85523796],\n",
       "       [0.87910324],\n",
       "       [0.11823592],\n",
       "       [0.12417701],\n",
       "       [0.87638366],\n",
       "       [0.01837948],\n",
       "       [0.09486175],\n",
       "       [0.91606253],\n",
       "       [0.93814427],\n",
       "       [0.45270053],\n",
       "       [0.13178629],\n",
       "       [0.40598294],\n",
       "       [0.1804395 ],\n",
       "       [0.09537107],\n",
       "       [0.09092167],\n",
       "       [0.717835  ],\n",
       "       [0.6501298 ],\n",
       "       [0.10865146],\n",
       "       [0.7312605 ],\n",
       "       [0.08513269],\n",
       "       [0.08025771],\n",
       "       [0.10630071],\n",
       "       [0.21633327],\n",
       "       [0.58196306],\n",
       "       [0.81737316],\n",
       "       [0.36549455],\n",
       "       [0.07852051],\n",
       "       [0.0976955 ],\n",
       "       [0.77511907],\n",
       "       [0.09368652],\n",
       "       [0.8793782 ],\n",
       "       [0.09083638],\n",
       "       [0.08321008],\n",
       "       [0.89031315],\n",
       "       [0.10980085],\n",
       "       [0.7955413 ],\n",
       "       [0.45312357],\n",
       "       [0.16915962],\n",
       "       [0.174355  ],\n",
       "       [0.10566953],\n",
       "       [0.7070713 ],\n",
       "       [0.68280363],\n",
       "       [0.81461686],\n",
       "       [0.6835648 ],\n",
       "       [0.89421964],\n",
       "       [0.60219234],\n",
       "       [0.08568245],\n",
       "       [0.91642296],\n",
       "       [0.06249791],\n",
       "       [0.08568245],\n",
       "       [0.1635443 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = relu_adam_model.predict(test_data) \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.078491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.367660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.039957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.527940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.649015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.166828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.592494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.160550</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Surv\n",
       "0  0.078491\n",
       "1  0.367660\n",
       "2  0.039957\n",
       "3  0.080476\n",
       "4  0.527940\n",
       "5  0.169780\n",
       "6  0.649015\n",
       "7  0.166828\n",
       "8  0.592494\n",
       "9  0.160550"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df = pd.DataFrame(data=predictions,columns=['Surv'])\n",
    "predict_df.head(10)\n",
    "# submission = pd.concat([passenferID,predict_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df.loc[(predict_df['Surv']>0.6),'Survived'] = 1\n",
    "predict_df.loc[(predict_df['Surv']<=0.6),'Survived'] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.0\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0\n",
       "6     1.0\n",
       "7     0.0\n",
       "8     0.0\n",
       "9     0.0\n",
       "10    0.0\n",
       "11    0.0\n",
       "12    1.0\n",
       "13    0.0\n",
       "14    1.0\n",
       "15    1.0\n",
       "16    0.0\n",
       "17    0.0\n",
       "18    0.0\n",
       "19    0.0\n",
       "20    0.0\n",
       "21    0.0\n",
       "22    1.0\n",
       "23    0.0\n",
       "24    1.0\n",
       "25    0.0\n",
       "26    1.0\n",
       "27    0.0\n",
       "28    0.0\n",
       "29    0.0\n",
       "30    0.0\n",
       "31    0.0\n",
       "32    0.0\n",
       "33    0.0\n",
       "34    0.0\n",
       "35    0.0\n",
       "36    1.0\n",
       "37    1.0\n",
       "38    0.0\n",
       "39    0.0\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "survived = predict_df['Survived']\n",
    "survived.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.concat([passengerID,survived],axis=1)\n",
    "submission.astype('int32')\n",
    "submission.to_csv(\"../submissions/NN_submission2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_0001 = Sequential()\n",
    "relu_adam_model_0001.add(Dense(256,input_dim=8,activation='relu'))\n",
    "relu_adam_model_0001.add(Dropout(0.2))\n",
    "relu_adam_model_0001.add(Dense(256,activation='relu'))\n",
    "relu_adam_model_0001.add(Dropout(0.2))\n",
    "relu_adam_model_0001.add(Dense(1,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_0001 = optimizers.Adam(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_adam_model_0001.compile(optimizer=adam_0001,loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 80 samples\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 0s 663us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 67us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 66us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 71us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 67us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 55us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 54us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 72us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 62us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 59us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 52us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 64us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 58us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 67us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 66us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 57us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 65us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 54us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 77us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 75us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 64us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 63us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 50us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 65us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 61us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 59us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 56us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 52us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 63us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 54us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 63us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 61us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 55us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 75us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 72us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 57us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 53us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 58us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 54us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 57us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 58us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 56us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 60us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 51us/step - loss: 9.7647 - accuracy: 0.3875 - val_loss: 9.9640 - val_accuracy: 0.3750\n"
     ]
    }
   ],
   "source": [
    "relu_adam_model_0001_history = relu_adam_model_0001.fit(X_train, y_train, epochs=50, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
